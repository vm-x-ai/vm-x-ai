---
sidebar_position: 4
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# Getting Started

This guide will help you get VM-X AI up and running locally using Docker Compose. This is the fastest way to start exploring VM-X AI's features.

## Prerequisites

Before you begin, ensure you have:

- **Docker** and **Docker Compose** installed
- At least **4GB of free RAM** available
- **Docker images** built or pulled:
  - `vmxai/api:latest`
  - `vmxai/ui:latest`

## Quick Start

### 1. Pull Docker Images

Pull the published Docker images:

```bash
docker pull vmxai/api:latest
docker pull vmxai/ui:latest
```

### 2. Create Docker Compose File

Create a file named `docker-compose.yml` in a directory of your choice:

```yaml
name: vm-x-ai-default
version: '1.0.0'

services:
  # -------------------------------
  # Next.js (UI)
  # -------------------------------
  ui:
    image: vmxai/ui:latest
    ports:
      - '3001:3001'
    environment:
      # Auth
      AUTH_URL: http://localhost:3001

      # Generated by `npx auth`. Read more: https://cli.authjs.dev
      AUTH_SECRET: 'iK0aiF1Hc57/P4Jym7Dz51sjlleE6onQXcAFBG7uvss'
      AUTH_OIDC_ISSUER: http://localhost:3000/oauth2
      AUTH_OIDC_CLIENT_ID: ui
      AUTH_OIDC_CLIENT_SECRET: ui
      AUTH_REDIRECT_PROXY_URL: http://localhost:3001/api/auth

      # API (network mode: host)
      API_BASE_URL: http://localhost:3000
    network_mode: host
    depends_on:
      - api

  # -------------------------------
  # Node.js (API)
  # -------------------------------
  api:
    image: vmxai/api:latest
    ports:
      - '3000:3000'
    depends_on:
      - postgres
      - redis
      - timeseriesdb
    network_mode: host
    environment:
      LOCAL: true
      BASE_URL: http://localhost:3000

      # PG Database
      DATABASE_HOST: localhost
      DATABASE_RO_HOST: localhost
      DATABASE_PORT: 5440
      DATABASE_USER: admin
      DATABASE_PASSWORD: password
      DATABASE_DB_NAME: vmxai

      # Redis (network mode: host)
      REDIS_HOST: localhost
      REDIS_PORT: 6379
      REDIS_MODE: 'single'

      # Vault
      ENCRYPTION_PROVIDER: libsodium

      # Libsodium openssl rand -base64 32
      # Only used for development
      LIBSODIUM_ENCRYPTION_KEY: mPpddUYSuhIkuLq6MqeARZSEBZiwWm0HwEGQD5YSMFc=

      # Timeseries Database
      COMPLETION_USAGE_PROVIDER: questdb

      # QuestDB
      QUESTDB_HOST: localhost
      QUESTDB_PORT: 8812
      QUESTDB_USER: admin
      QUESTDB_PASSWORD: password
      QUESTDB_DB_NAME: vmxai

      # UI
      UI_BASE_URL: http://localhost:3001

      OTEL_LOG_LEVEL: error
      OTEL_EXPORTER_OTLP_ENDPOINT: http://localhost:4318

  # -------------------------------
  # Postgres (Database)
  # -------------------------------
  postgres:
    image: postgres
    ports:
      - '5440:5432'
    environment:
      POSTGRES_USER: 'admin'
      POSTGRES_PASSWORD: password
      POSTGRES_DB: vmxai

  # -------------------------------
  # Redis (Cache)
  # -------------------------------
  redis:
    image: redis:7
    ports:
      - '6379:6379'
    network_mode: host

  # -------------------------------
  # QuestDB (Timeseries Database)
  # -------------------------------
  timeseriesdb:
    image: questdb/questdb:9.1.1
    environment:
      QDB_PG_USER: admin
      QDB_PG_PASSWORD: password
      QDB_PG_DATABASE: vmxai
    ports:
      - '9000:9000'
      - '8812:8812'
```

### 3. Start Services

Start all services:

```bash
docker compose up -d
```

:::info Network Mode: Host
The `network_mode: host` configuration is used for the UI, API, and Redis services to simplify networking in local development. This allows services to communicate using `localhost` directly. In production deployments (Kubernetes, ECS), you should use standard Docker networking instead.

**Note for Mac users**: Host networking is available on Docker Desktop for Mac starting with version 4.34. To enable it, go to **Settings** → **Resources** → **Network** and check the **"Enable host networking"** option.
:::

This will start:

- **UI** on port `3001`
- **API** on port `3000`
- **PostgreSQL** on port `5440`
- **Redis** on port `6379`
- **QuestDB** on port `9000` (web console) and `8812` (PostgreSQL wire)

### 4. Wait for Services to Be Ready

Wait a few moments for all services to start. You can check the status:

```bash
docker compose ps
```

Check the API logs to ensure it's ready:

```bash
docker compose logs api | grep "Application is running"
```

### 5. Access the Application

Open your browser and navigate to:

**UI**: http://localhost:3001

The default credentials are:

- **Username**: `admin`
- **Password**: `admin`

:::warning
Change the default credentials immediately after first login!
:::

### API Documentation

VM-X AI provides interactive API documentation via Swagger UI:

**Swagger UI**: http://localhost:3000/docs

The Swagger UI provides:

- Complete API reference
- Interactive API testing
- Request/response schemas
- Authentication testing

## What's Next?

After logging in, you'll be guided through the setup process:

1. **Create a Workspace** (if none exists)
2. **Create an Environment** (if none exists)
3. **Create an AI Connection** - Add your first AI provider
4. **Create an AI Resource** - Configure your first resource
5. **Generate an API Key** - Get an API key to use with your applications

## Using the OpenAI-Compatible API

VM-X AI uses workspace and environment isolation for the completion API. The API endpoint includes the workspace ID and environment ID in the path.

### Getting Your Workspace and Environment IDs

1. Log in to the UI at http://localhost:3001

![Login Page](/pages/login-page.png)

2. Navigate to your workspace and environment
3. Click on the **SDK** tab in the UI
4. The SDK tab provides all the details you need, including:
   - Workspace ID
   - Environment ID
   - API Key
   - Complete code examples for Python, Node.js, and other languages

The SDK tab shows ready-to-use code snippets with your specific workspace and environment IDs pre-filled.

### Code Examples

<Tabs>
  <TabItem value="python" label="Python">

```python
from openai import OpenAI

workspace_id = "6c41dc1b-910c-4358-beef-2c609d38db31"
environment_id = "6c1957ca-77ca-49b3-8fa1-0590281b8b44"
resource_name = "your-resource-name"  # The name of your AI Resource

client = OpenAI(
    api_key="your-vmx-api-key-here",
    base_url=f"http://localhost:3000/v1/completion/{workspace_id}/{environment_id}"
)

response = client.chat.completions.create(
    model=resource_name,
    messages=[
        {"role": "user", "content": "Hello, world!"}
    ]
)

print(response.choices[0].message.content)
```

  </TabItem>
  <TabItem value="nodejs" label="Node.js">

```javascript
import OpenAI from 'openai';

const workspaceId = '6c41dc1b-910c-4358-beef-2c609d38db31';
const environmentId = '6c1957ca-77ca-49b3-8fa1-0590281b8b44';
const resourceName = 'your-resource-name'; // The name of your AI Resource

const openai = new OpenAI({
  apiKey: 'your-vmx-api-key-here',
  baseURL: `http://localhost:3000/v1/completion/${workspaceId}/${environmentId}`,
});

const completion = await openai.chat.completions.create({
  model: resourceName,
  messages: [{ role: 'user', content: 'Hello, world!' }],
});

console.log(completion.choices[0].message.content);
```

  </TabItem>
  <TabItem value="curl" label="cURL">

```bash
curl http://localhost:3000/v1/completion/{workspaceId}/{environmentId}/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-vmx-api-key-here" \
  -d '{
    "model": "your-resource-name",
    "messages": [
      {"role": "user", "content": "Hello, world!"}
    ]
  }'
```

  </TabItem>
</Tabs>

## Additional Docker Compose Configurations

For more advanced configurations, see the [examples/docker-compose](https://github.com/vm-x-ai/vm-x-ai/tree/main/examples/docker-compose) directory in the repository, which contains several pre-configured setups:

### Available Configurations

1. **Default Configuration** (`default.docker-compose.yml`)

   - Basic setup with all core services
   - PostgreSQL, Redis (single node), QuestDB
   - Libsodium encryption

2. **OpenTelemetry Configuration** (`otel.docker-compose.yml`)

   - Full observability stack
   - OpenTelemetry Collector, Jaeger, Prometheus, Loki, Grafana
   - See [README](https://github.com/vm-x-ai/vm-x-ai/blob/main/examples/docker-compose/README.md) for access URLs

3. **AWS Services Configuration** (`aws.docker-compose.yml`)

   - Production-like setup using AWS services
   - AWS KMS for encryption
   - AWS Timestream for time-series data
   - Requires AWS credentials configured

4. **Redis Cluster Configuration** (`redis-cluster.docker-compose.yml`)
   - Redis cluster mode for high availability
   - 3-node Redis cluster
   - QuestDB

For detailed information about all configurations, see the [Docker Compose Examples README](https://github.com/vm-x-ai/vm-x-ai/blob/main/examples/docker-compose/README.md).

## Configuration

### Environment Variables

Key environment variables for the API service:

| Variable                    | Description                                          | Default                 |
| --------------------------- | ---------------------------------------------------- | ----------------------- |
| `BASE_URL`                  | API base URL                                         | `http://localhost:3000` |
| `DATABASE_HOST`             | PostgreSQL host                                      | `localhost`             |
| `DATABASE_PORT`             | PostgreSQL port                                      | `5440`                  |
| `REDIS_HOST`                | Redis host                                           | `localhost`             |
| `REDIS_PORT`                | Redis port                                           | `6379`                  |
| `REDIS_MODE`                | Redis mode (`single` or `cluster`)                   | `single`                |
| `ENCRYPTION_PROVIDER`       | Encryption provider (`libsodium` or `aws-kms`)       | `libsodium`             |
| `COMPLETION_USAGE_PROVIDER` | Time-series provider (`questdb` or `aws-timestream`) | `questdb`               |
| `OTEL_ENABLED`              | Enable OpenTelemetry                                 | `false`                 |

### Database Credentials

Default credentials (change in production!):

- **PostgreSQL**:

  - User: `admin`
  - Password: `password`
  - Database: `vmxai`

- **QuestDB**:

  - User: `admin`
  - Password: `password`
  - Database: `vmxai`

- **Redis**: No password (development only)

## Stopping Services

To stop all services:

```bash
docker compose down
```

To stop and remove volumes (⚠️ deletes data):

```bash
docker compose down -v
```

## Troubleshooting

### Port Conflicts

If you encounter port conflicts, you can modify the port mappings in the compose file:

```yaml
ports:
  - '3001:3001' # Change 3001 to an available port
```

### Services Not Starting

Check service logs:

```bash
# Check all logs
docker compose logs

# Check specific service
docker compose logs api
docker compose logs ui
```

### Database Connection Issues

Ensure PostgreSQL is ready before the API starts:

```bash
# Check PostgreSQL status
docker compose ps postgres

# Check PostgreSQL logs
docker compose logs postgres
```

## Next Steps

Now that you have VM-X AI running locally:

1. **[Create Your First AI Connection](../features/ai-connections)** - Add an AI provider
2. **[Create Your First AI Resource](../features/ai-resources/)** - Configure routing and fallback
3. **[Explore Features](../features/workspaces-environments)** - Learn about all available features
4. **[Deploy to Production](../deployment/minikube)** - Deploy to Kubernetes or AWS

## Additional Resources

- [Docker Compose Examples README](https://github.com/vm-x-ai/vm-x-ai/blob/main/examples/docker-compose/README.md) - Detailed information about all configurations
- [Core Components](./core-components.md) - Understand AI Connections and Resources
- [Architecture](./architecture.md) - Learn about the technical stack
